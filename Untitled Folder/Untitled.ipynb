{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [2,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x,w):\n",
    "    return x*w\n",
    "#loss\n",
    "def loss(x,w,y):\n",
    "    ypre = forward(x,w)\n",
    "    return (ypre-y)*(ypre-y)\n",
    "\n",
    "#gradient\n",
    "def gradient(w,x,y):\n",
    "    gra = 2*x**2*w - 2*x*y\n",
    "    print(\"gradient: \",gra)\n",
    "    return gra\n",
    "# update weight\n",
    "def update_weight(x,w,rate,y):\n",
    "    gra = w-rate*(gradient(w,x,y))\n",
    "    return gra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "def find_w(x_data,y_data):\n",
    "    w = 10\n",
    "    print(\"before training:\",4,forward(4,w))\n",
    "    for j in range(100):\n",
    "        print(\"loop: \",j)\n",
    "        for i in range(len(x_data)):\n",
    "            w = update_weight(x_data[i],w,0.1,y_data[i])\n",
    "        print(\"weight:\"+ str(w)+\" epoch: \"+str(j)+\" loss: \"+str(loss(w,x_data[i],y_data[i])))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x,w):\n",
    "    return w*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training: 4 40\n",
      "loop:  0\n",
      "gradient:  16\n",
      "gradient:  51.2\n",
      "gradient:  23.039999999999992\n",
      "weight:0.976 epoch: 0 loss: 9.437184\n",
      "loop:  1\n",
      "gradient:  -2.048\n",
      "gradient:  -6.553599999999999\n",
      "gradient:  -2.9491200000000006\n",
      "weight:2.131072 epoch: 1 loss: 0.15461882265600052\n",
      "loop:  2\n",
      "gradient:  0.26214400000000015\n",
      "gradient:  0.8388607999999991\n",
      "gradient:  0.3774873599999964\n",
      "weight:1.983222784 epoch: 2 loss: 0.002533274790395927\n",
      "loop:  3\n",
      "gradient:  -0.033554431999999856\n",
      "gradient:  -0.10737418239999919\n",
      "gradient:  -0.048318382079997946\n",
      "weight:2.0021474836479998 epoch: 3 loss: 4.150517416583762e-05\n",
      "loop:  4\n",
      "gradient:  0.004294967295999541\n",
      "gradient:  0.01374389534719711\n",
      "gradient:  0.006184752906236213\n",
      "weight:1.9997251220930563 epoch: 4 loss: 6.800207735317125e-07\n",
      "loop:  5\n",
      "gradient:  -0.000549755813887387\n",
      "gradient:  -0.0017592186044392832\n",
      "gradient:  -0.0007916483719938583\n",
      "weight:2.0000351843720887 epoch: 5 loss: 1.1141460353494078e-08\n",
      "loop:  6\n",
      "gradient:  7.036874417742922e-05\n",
      "gradient:  0.00022517998136706296\n",
      "gradient:  0.00010133099161180326\n",
      "weight:1.999995496400373 epoch: 6 loss: 1.8254168641513496e-10\n",
      "loop:  7\n",
      "gradient:  -9.007199254007503e-06\n",
      "gradient:  -2.8823037613534552e-05\n",
      "gradient:  -1.2970366924491827e-05\n",
      "weight:2.000000576460752 epoch: 7 loss: 2.9907629875959394e-12\n",
      "loop:  8\n",
      "gradient:  1.1529215040440022e-06\n",
      "gradient:  3.6893488122302642e-06\n",
      "gradient:  1.660206962128541e-06\n",
      "weight:1.999999926213024 epoch: 8 loss: 4.900066036095286e-14\n",
      "loop:  9\n",
      "gradient:  -1.4757395216946634e-07\n",
      "gradient:  -4.7223664623174955e-07\n",
      "gradient:  -2.1250649240300845e-07\n",
      "weight:2.000000009444733 epoch: 9 loss: 8.028268322387536e-16\n",
      "loop:  10\n",
      "gradient:  1.888946599137853e-08\n",
      "gradient:  6.044628975132582e-08\n",
      "gradient:  2.720083358553893e-08\n",
      "weight:1.9999999987910742 epoch: 10 loss: 1.3153512139340274e-17\n",
      "loop:  11\n",
      "gradient:  -2.4178516966344432e-09\n",
      "gradient:  -7.737124718687483e-09\n",
      "gradient:  -3.481709143215994e-09\n",
      "weight:2.000000000154743 epoch: 11 loss: 2.1550824460290137e-19\n",
      "loop:  12\n",
      "gradient:  3.0948577034450864e-10\n",
      "gradient:  9.903544651024276e-10\n",
      "gradient:  4.4565950929609244e-10\n",
      "weight:1.999999999980193 epoch: 12 loss: 3.5308448583498934e-21\n",
      "loop:  13\n",
      "gradient:  -3.9614089786255136e-11\n",
      "gradient:  -1.2676437677328067e-10\n",
      "gradient:  -5.704237082682084e-11\n",
      "weight:2.0000000000025353 epoch: 13 loss: 5.785671224136635e-23\n",
      "loop:  14\n",
      "gradient:  5.070610598068015e-12\n",
      "gradient:  1.6225243371081888e-11\n",
      "gradient:  7.297273896256229e-12\n",
      "weight:1.9999999999996758 epoch: 14 loss: 9.458639468826237e-25\n",
      "loop:  15\n",
      "gradient:  -6.483702463810914e-13\n",
      "gradient:  -2.0747847884194925e-12\n",
      "gradient:  -9.379164112033322e-13\n",
      "weight:2.0000000000000417 epoch: 15 loss: 1.5683343656698936e-26\n",
      "loop:  16\n",
      "gradient:  8.348877145181177e-14\n",
      "gradient:  2.6645352591003757e-13\n",
      "gradient:  1.2079226507921703e-13\n",
      "weight:1.9999999999999947 epoch: 16 loss: 2.5559093329160782e-28\n",
      "loop:  17\n",
      "gradient:  -1.0658141036401503e-14\n",
      "gradient:  -3.375077994860476e-14\n",
      "gradient:  -1.4210854715202004e-14\n",
      "weight:2.0000000000000004 epoch: 17 loss: 3.1554436208840472e-30\n",
      "loop:  18\n",
      "gradient:  8.881784197001252e-16\n",
      "gradient:  3.552713678800501e-15\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 18 loss: 0.0\n",
      "loop:  19\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 19 loss: 0.0\n",
      "loop:  20\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 20 loss: 0.0\n",
      "loop:  21\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 21 loss: 0.0\n",
      "loop:  22\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 22 loss: 0.0\n",
      "loop:  23\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 23 loss: 0.0\n",
      "loop:  24\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 24 loss: 0.0\n",
      "loop:  25\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 25 loss: 0.0\n",
      "loop:  26\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 26 loss: 0.0\n",
      "loop:  27\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 27 loss: 0.0\n",
      "loop:  28\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 28 loss: 0.0\n",
      "loop:  29\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 29 loss: 0.0\n",
      "loop:  30\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 30 loss: 0.0\n",
      "loop:  31\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 31 loss: 0.0\n",
      "loop:  32\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 32 loss: 0.0\n",
      "loop:  33\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 33 loss: 0.0\n",
      "loop:  34\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 34 loss: 0.0\n",
      "loop:  35\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 35 loss: 0.0\n",
      "loop:  36\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 36 loss: 0.0\n",
      "loop:  37\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 37 loss: 0.0\n",
      "loop:  38\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 38 loss: 0.0\n",
      "loop:  39\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 39 loss: 0.0\n",
      "loop:  40\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 40 loss: 0.0\n",
      "loop:  41\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 41 loss: 0.0\n",
      "loop:  42\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 42 loss: 0.0\n",
      "loop:  43\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 43 loss: 0.0\n",
      "loop:  44\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 44 loss: 0.0\n",
      "loop:  45\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 45 loss: 0.0\n",
      "loop:  46\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 46 loss: 0.0\n",
      "loop:  47\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 47 loss: 0.0\n",
      "loop:  48\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 48 loss: 0.0\n",
      "loop:  49\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 49 loss: 0.0\n",
      "loop:  50\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 50 loss: 0.0\n",
      "loop:  51\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 51 loss: 0.0\n",
      "loop:  52\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 52 loss: 0.0\n",
      "loop:  53\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 53 loss: 0.0\n",
      "loop:  54\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 54 loss: 0.0\n",
      "loop:  55\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 55 loss: 0.0\n",
      "loop:  56\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 56 loss: 0.0\n",
      "loop:  57\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 57 loss: 0.0\n",
      "loop:  58\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 58 loss: 0.0\n",
      "loop:  59\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 59 loss: 0.0\n",
      "loop:  60\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 60 loss: 0.0\n",
      "loop:  61\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 61 loss: 0.0\n",
      "loop:  62\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 62 loss: 0.0\n",
      "loop:  63\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 63 loss: 0.0\n",
      "loop:  64\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 64 loss: 0.0\n",
      "loop:  65\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 65 loss: 0.0\n",
      "loop:  66\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 66 loss: 0.0\n",
      "loop:  67\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 67 loss: 0.0\n",
      "loop:  68\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 68 loss: 0.0\n",
      "loop:  69\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 69 loss: 0.0\n",
      "loop:  70\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 70 loss: 0.0\n",
      "loop:  71\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 71 loss: 0.0\n",
      "loop:  72\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 72 loss: 0.0\n",
      "loop:  73\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 73 loss: 0.0\n",
      "loop:  74\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 74 loss: 0.0\n",
      "loop:  75\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 75 loss: 0.0\n",
      "loop:  76\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 76 loss: 0.0\n",
      "loop:  77\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 77 loss: 0.0\n",
      "loop:  78\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 78 loss: 0.0\n",
      "loop:  79\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 79 loss: 0.0\n",
      "loop:  80\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 80 loss: 0.0\n",
      "loop:  81\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 81 loss: 0.0\n",
      "loop:  82\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 82 loss: 0.0\n",
      "loop:  83\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 83 loss: 0.0\n",
      "loop:  84\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 84 loss: 0.0\n",
      "loop:  85\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 85 loss: 0.0\n",
      "loop:  86\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 86 loss: 0.0\n",
      "loop:  87\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 87 loss: 0.0\n",
      "loop:  88\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 88 loss: 0.0\n",
      "loop:  89\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 89 loss: 0.0\n",
      "loop:  90\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 90 loss: 0.0\n",
      "loop:  91\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 91 loss: 0.0\n",
      "loop:  92\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 92 loss: 0.0\n",
      "loop:  93\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 93 loss: 0.0\n",
      "loop:  94\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 94 loss: 0.0\n",
      "loop:  95\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 95 loss: 0.0\n",
      "loop:  96\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 96 loss: 0.0\n",
      "loop:  97\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 97 loss: 0.0\n",
      "loop:  98\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 98 loss: 0.0\n",
      "loop:  99\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "gradient:  0.0\n",
      "weight:2.0 epoch: 99 loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "w = find_w(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(4,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_data = [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(linear(1,w))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
